{
  "cells": [
    {
      "metadata": {
        "_uuid": "db1db4bc191c63f9192a90665682c5be676103ce"
      },
      "cell_type": "markdown",
      "source": "# About \nThis notebook demonstrates one way to setup a UNet using the pretrained ResNet50 encoder from Keras.  The input images are scaled first to `224 x 224` by doubling the size and padding the rest.  In this notebook I have kept simple all other details of training, augmentation, and prediction.  Feel free to extend this notebook by adding features. "
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport gc\ngc.enable() \n\nimport matplotlib.pyplot as plt \nimport os \nimport time \n\n# This stops pandas from spitting \n# out warnings at us. \nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy.ndimage.filters import gaussian_filter\nfrom scipy.ndimage.interpolation import map_coordinates\nfrom skimage.io import imread\nfrom skimage.transform import resize\n\nimport tensorflow as tf \n\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.preprocessing.image import load_img, ImageDataGenerator\nfrom keras import Model\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam, SGD\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, SpatialDropout2D \nfrom keras.layers import UpSampling2D, Concatenate, Dropout, Lambda, BatchNormalization, Add, ZeroPadding2D\nfrom keras.layers import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras import backend as K \n\nfrom tqdm import tqdm_notebook\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de12fb77f4ce262eaaa0655479912a5726cd733b"
      },
      "cell_type": "code",
      "source": "BASE_DIRECTORY = '../input/'\n\n# Image sizes for loading. \nIMAGE_WIDTH, IMAGE_HEIGHT = 101, 101\nIMAGE_CHANNELS = 3\n\n# U-net will be applied later, and this is the \n# input size that we will use. \nRESIZED_WIDTH, RESIZED_HEIGHT = 224, 224",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "059050aef1815c75dda7a480e7d56517ba738061"
      },
      "cell_type": "code",
      "source": "def upscale(input_image, resized_shape=(224,224,3)):\n    new_image = np.zeros(shape=resized_shape)\n    \n    if len(input_image.shape) == 3:\n        height, width, channels = input_image.shape\n    else:\n        height, width = input_image.shape\n        channels = 1\n    \n    if channels > 1:\n        new_image[11:213, 11:213, :] = resize(input_image, (202, 202, 3))\n    else:\n        new_image[11:213, 11:213, :] = resize(input_image, (202, 202, 1))\n\n    return new_image\n\ndef downscale(input_image):\n    height, width, channels = input_image.shape\n    return resize(input_image[11:213, 11:213, :], (101, 101, channels))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9975b048fa29ca7128da65d1bca608ac30bdcc5"
      },
      "cell_type": "code",
      "source": "def prepare_training_sample(path_to_train='../input/train/', bad_ids=None, sample_size=100):\n    \n    # Get list of images and masks. \n    image_files = glob.glob(path_to_train + 'images/*.png')\n    extract_id = lambda x: x.split('.png')[0].split('/')[-1]\n    image_ids = [extract_id(file) for file in image_files]\n\n    if bad_ids is not None:\n        images_ids = [id for id in image_ids if id not in bad_ids]\n    \n    sample_size = (sample_size if sample_size < len(image_ids) else len(image_ids))\n\n    x = np.zeros(shape=(sample_size, 224, 224, 3))\n    y = np.zeros(shape=(sample_size, 224, 224, 1))\n    \n    for index, id in enumerate(image_ids[:sample_size]):\n        x[index,:,:,:] = upscale(np.array(load_img(path_to_train + 'images/' + id + '.png')) / 255)\n        y[index,:,:,:] = upscale(np.array(load_img(path_to_train + 'masks/'  + id + '.png', grayscale=True)) / 255, resized_shape=(224,224,1))\n    \n    return x, y",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8f07154d5894e441136dffa6769b5b3427cd12a"
      },
      "cell_type": "code",
      "source": "x, y = prepare_training_sample(sample_size=4001) # Load everything (there are 4000 images)\nsalt_fraction = np.sum(np.sum(y, axis=1), axis=1)\nsalt_fraction = np.digitize(salt_fraction, np.linspace(0,1,10))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6474a713a39ae1062d1cf39bca0c5f5f7f626b8b"
      },
      "cell_type": "code",
      "source": "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.1, stratify=salt_fraction)\ndel x, y\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1234dcc63094ba6e3f084ad2f5d7d9b3e67ed16"
      },
      "cell_type": "code",
      "source": "# The metric function from: https://www.kaggle.com/shaojiaxin/u-net-with-simple-resnet-blocks-v2-new-loss\ndef get_iou_vector(A, B):\n    batch_size = A.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch] > 0, B[batch] > 0\n        \n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = (np.sum(intersection > 0) + 1e-10 ) / (np.sum(union > 0) + 1e-10)\n        thresholds = np.arange(0.5, 1, 0.05)\n        \n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        \n        metric.append(np.mean(s))\n    return np.mean(metric)\n\ndef my_iou_metric(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)\n\ndef my_iou_metric_2(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0], tf.float64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "599d772fe7c5e70ee8efd2208e15cfb039176bda"
      },
      "cell_type": "code",
      "source": "def get_unet_resnet(input_shape, trainable=False):\n    \n    input_layer = Input(input_shape)\n    resnet_base = ResNet50(input_shape=input_shape, include_top=False, \n                           input_tensor=input_layer, weights='imagenet')\n    \n    for l in resnet_base.layers:\n        l.trainable = trainable\n\n    conv1 = resnet_base.get_layer(\"activation_1\").output\n    conv2 = resnet_base.get_layer(\"activation_10\").output\n    conv3 = resnet_base.get_layer(\"activation_22\").output\n    conv4 = resnet_base.get_layer(\"activation_40\").output\n    conv5 = resnet_base.get_layer(\"activation_49\").output\n\n    middle_layer = Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu')(conv5)\n    middle_layer = Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu')(middle_layer)    \n    \n    upconv_5 = UpSampling2D()(middle_layer)\n    upconv_5 = Concatenate()([conv4, upconv_5])\n    upconv_5 = Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_5)\n    upconv_5 = BatchNormalization()(upconv_5)\n    upconv_5 = Conv2D(256, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_5)     \n    upconv_5 = BatchNormalization()(upconv_5)\n\n    upconv_4 = UpSampling2D()(upconv_5)\n    upconv_4 = Concatenate()([conv3, upconv_4])\n    upconv_4 = Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_4) \n    upconv_4 = BatchNormalization()(upconv_4)\n    upconv_4 = Conv2D(128, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_4) \n    upconv_4 = BatchNormalization()(upconv_4)\n        \n    upconv_3 = UpSampling2D()(upconv_4)\n    upconv_3 = Concatenate()([ZeroPadding2D(((1,0),(0,1)))(conv2), upconv_3])\n    upconv_3 = Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_3) \n    upconv_3 = BatchNormalization()(upconv_3)\n    upconv_3 = Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_3) \n    upconv_3 = BatchNormalization()(upconv_3)\n        \n    upconv_2 = UpSampling2D()(upconv_3)\n    upconv_2 = Concatenate()([conv1, upconv_2])\n    upconv_2 = Conv2D(32, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_2)     \n    upconv_2 = BatchNormalization()(upconv_2)\n    upconv_2 = Conv2D(32, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_2) \n    upconv_2 = BatchNormalization()(upconv_2)\n    \n    upconv_1 = UpSampling2D()(upconv_2)\n    upconv_1 = Concatenate()([input_layer, upconv_1])\n    upconv_1 = Conv2D(16, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_1) \n    upconv_1 = BatchNormalization()(upconv_1)\n    upconv_1 = Conv2D(16, (3,3), strides=(1,1), padding='same', activation='relu')(upconv_1) \n    upconv_1 = BatchNormalization()(upconv_1)\n    output_layer = Conv2D(1, (3,3), padding='same', activation='sigmoid')(upconv_1)\n\n    model = Model(input_layer, output_layer)\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9e1336be326074c90584ed8f903492db2c39583"
      },
      "cell_type": "code",
      "source": "# Credit: Github user kylemcdonald\n# https://github.com/keras-team/keras/issues/1625\nclass TimedStopping(Callback):\n    '''Stop training when enough time has passed.\n    # Arguments\n        seconds: maximum time before stopping.\n        verbose: verbosity mode.\n    '''\n    def __init__(self, seconds=None, verbose=0):\n        super(Callback, self).__init__()\n\n        self.start_time = 0\n        self.seconds = seconds\n        self.verbose = verbose\n\n    def on_train_begin(self, logs={}):\n        self.start_time = time.time()\n\n    def on_epoch_end(self, epoch, logs={}):\n        if time.time() - self.start_time > self.seconds:\n            self.model.stop_training = True\n            if self.verbose:\n                print('Stopping after %s seconds.' % self.seconds)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90539f978e179d7d50990dcf485882ea83cd779d",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "early_stopping = EarlyStopping(patience = 15, verbose=1)\nmodel_checkpoint = ModelCheckpoint('keras.h5', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(factor=1e-1, patience=5, min_lr=1e-6, verbose=1)\ntimed_stopping = TimedStopping(seconds = 1 * 3600) \n\nepochs = 100\nbatch_size = 32\n\nmodel = get_unet_resnet((224, 224, 3), trainable = False)\noptimizer = Adam(lr=1e-2)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[my_iou_metric])\n\nhistory = model.fit(\n    x_train, y_train, \n    validation_data=[x_valid, y_valid], \n    epochs=epochs,\n    batch_size=batch_size,\n    callbacks=[early_stopping, model_checkpoint, reduce_lr, timed_stopping], \n    shuffle=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "592f90af9328fb6cde51895a0c8127978d170547"
      },
      "cell_type": "code",
      "source": "epochs = 100\nbatch_size = 32\ntimed_stopping = TimedStopping(seconds = 4 * 3600) \n\nfor layer in model.layers:\n    layer.trainable = True\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[my_iou_metric])\nhistory = model.fit(\n    x_train, y_train, \n    validation_data=[x_valid, y_valid], \n    epochs=epochs,\n    batch_size=batch_size,\n    callbacks=[early_stopping, model_checkpoint, reduce_lr, timed_stopping], \n    shuffle=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "03929602987334405cbf39868c3cab9ca80d2d00"
      },
      "cell_type": "code",
      "source": "fig = plt.figure( figsize=(8,6) )\nax = fig.add_subplot(1,1,1)\nax.plot(history.history['loss'], label='Train')\nax.plot(history.history['val_loss'], label='Validation')\nax.set_xlabel('Epoch')\nax.legend(frameon=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a9886e3a27dcab4cc4eaebbcfc96c329b3a96cb0"
      },
      "cell_type": "markdown",
      "source": "### Free Memory Up\nIf you're planning to do anything with the validation dataset, that should be added above this cell."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0b194b4d91714e7ed5ff8beff0057db0217a185"
      },
      "cell_type": "code",
      "source": "del x_train, y_train, x_valid, y_valid\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "789c0da451d616a08beb3083babba8a47dd05f99"
      },
      "cell_type": "code",
      "source": "model = load_model('keras.h5', custom_objects={'mean_iou':mean_iou})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "28f967973bfb2200d9e890d301b976f3a57324c3"
      },
      "cell_type": "code",
      "source": "def rle_encode(im):\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8ca9ca77cf3f24f445564ec726ed58f422e3a51"
      },
      "cell_type": "code",
      "source": "def batch_predict(testing_ids, testing_path, batch_size=1000, threshold=0.5, model=None):\n    ''' Predict batches of images to save memory. '''\n        \n    total_batches = len(testing_ids) // batch_size\n    \n    data_store = []\n    for batch_index in tqdm_notebook(range(total_batches), total=total_batches):\n        if batch_index < (total_batches - 1):\n            ids = testing_ids[batch_index * batch_size:(batch_index + 1) * batch_size]\n        else:            \n            ids = testing_ids[batch_index * batch_size:]\n\n        test_df = pd.DataFrame({'id':ids})\n        test_df['image'] = [np.array(load_img(\"{}test/images/{}.png\".format(testing_path, id))) / 255 for id in ids]\n        test_df['image'] = test_df['image'].apply(upscale)\n        x_batch = np.array(test_df['image'].values.tolist()).reshape(len(ids), 224, 224, 3)\n        y_pred = 0.5 * (model.predict(x_batch) + model.predict(x_batch[:,:,::-1,:])[:,:,::-1,:])\n        y_pred = np.round(y_pred > threshold)\n        y_pred = np.array([downscale(y) for y in y_pred], dtype=np.int8)\n        test_df['rle_mask'] = [rle_encode(y) for y in y_pred]\n        data_store.append(test_df.drop(columns=['image']))\n        \n    return pd.concat(data_store)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74d69d083e64e4e2c31bffba2b6beb1e6c9df1b1"
      },
      "cell_type": "code",
      "source": "path_to_test = '../input/'\nextract_id = lambda x: x.split('.png')[0].split('/')[-1]\ntesting_ids = [extract_id(f) for f in glob.glob(path_to_test+'test/images/*.png')]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c3fb9fa86de1288705c78be552a1c316ee4a06f5"
      },
      "cell_type": "code",
      "source": "pred = batch_predict(testing_ids, path_to_test, batch_size=100, model=model, threshold=0.5)\npred.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8b433a42339076f033fa9cc69682a0c4d63959e0"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}