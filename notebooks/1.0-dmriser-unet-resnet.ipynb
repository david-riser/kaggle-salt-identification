{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport gc\ngc.enable() \n\nimport matplotlib.pyplot as plt \nimport os \nimport tensorflow as tf \n\n# This stops pandas from spitting \n# out warnings at us. \nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy.ndimage.filters import gaussian_filter\nfrom scipy.ndimage.interpolation import map_coordinates\nfrom skimage.io import imread\nfrom skimage.transform import resize\n\nfrom tqdm import tqdm_notebook\n\nfrom keras.preprocessing.image import load_img, ImageDataGenerator\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam, SGD\nfrom keras import optimizers\nfrom keras.layers import Activation, Input, Conv2D, Conv2DTranspose, MaxPooling2D, SpatialDropout2D \nfrom keras.layers import UpSampling2D, Concatenate, Dropout, Lambda, BatchNormalization, Add, ZeroPadding2D\nfrom keras.layers import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras import backend as K \n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de12fb77f4ce262eaaa0655479912a5726cd733b"
      },
      "cell_type": "code",
      "source": "RANDOM_SEED = 555\nnp.random.seed(RANDOM_SEED)\n\nBASE_DIRECTORY = '../input/'\n\n# Image sizes for loading. \nIMAGE_WIDTH, IMAGE_HEIGHT = 101, 101\nIMAGE_CHANNELS = 1\n\n# Netowrk parameters \nMAX_EPOCHS        = 100\nEPOCHS_1          = 75\nBATCH_SIZE_1      = 128\nBATCH_SIZE_2      = 64\nBATCHES_PER_EPOCH = 200",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcd3c4a8759cf55cc1c4f7fb21928e6782106a0e"
      },
      "cell_type": "code",
      "source": "bad_ids = ['00950d1627', '0280deb8ae', '09152018c4', \n           '09b9330300', '130229ec15', '15d76f1672', \n           '1eaf42beee', '23afbccfb5', '24522ec665', \n           '285f4b2e82', '2bc179b78c', '2f746f8726', \n           '33887a0ae7', '33dfce3a76', '36ad52a2e8', \n           '3975043a11', '39cd06da7d', '3cb59a4fdc', \n           '403cb8f4b3', '483b35d589', '4f5df40ab2', \n           '4fbda008c7', '4fdc882e4b', '50d3073821', \n           '52667992f8', '52ac7bb4c1', '5b217529e7', \n           '608567ed23', '60dccbc52f', '62aad7556c', \n           '62d30854d7', '640ceb328a', '7f0825a2f0', \n           '80a458a2b6', '81fa3d59b8', '834861f1b6', \n           '849881c690', '876e6423e6', '88a5c49514', \n           '89dfb7ba1d', '9067effd34', '916aff36ae', \n           '919bc0e2ba', '937ea43a65', '93a1541218', \n           '95f6e2b2d1', '96216dae3b', '96523f824a', \n           '99ee31b5bc', '9a4b15919d', '9eb4a10b98', \n           'a266a2a9df', 'a6625b8937', 'a9ee40cf0d', \n           'aeba5383e4', 'b1be1fa682', 'b24d3673e1', \n           'b35b1b412b', 'b525824dfc', 'b8a9602e21', \n           'ba1287cb48', 'be90ab3e56', 'c2973c16f1', \n           'c387a012fc', 'c98dfd50ba', 'caccd6708f', \n           'd0bbe4fd97', 'd4d2ed6bd2', 'd4d34af4f7', \n           'd9a52dc263', 'dd6a04d456', 'ddcb457a07', \n           'de7202d286', 'e12cd094a6', 'e73ed6e7f2', \n           'f0c401b64b', 'f19b7d20bb', 'f641699848', \n           'f6e87c1458', 'f7380099f6', 'f75842e215', \n           'fb3392fee0', 'fb47e8e74e', 'fd63516ff4', \n           'febd1d2a67']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9975b048fa29ca7128da65d1bca608ac30bdcc5"
      },
      "cell_type": "code",
      "source": "def prepare_training_sample(path_to_train='../input/train', bad_ids=None, sample_size=100):\n    \n    # Get list of images and masks. \n    image_files = glob.glob(path_to_train + '/images/*.png')\n    extract_id = lambda x: x.split('.png')[0].split('/')[-1]\n    image_ids = [extract_id(file) for file in image_files]\n\n    if bad_ids is not None:\n        images_ids = [id for id in image_ids if id not in bad_ids]\n    \n    sample_size = (sample_size if sample_size < len(image_ids) else len(image_ids))\n\n    x = np.zeros(shape=(sample_size, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n    y = np.zeros(shape=(sample_size, IMAGE_HEIGHT, IMAGE_WIDTH, 1))\n\n    for index, id in enumerate(image_ids[:sample_size]):\n        x[index, :, :, :] = np.array(load_img('{}/images/{}.png'.format(path_to_train, id), grayscale=True), dtype=np.float32).reshape(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS) / 255\n        y[index, :, :, :] = np.array(load_img('{}/masks/{}.png'.format(path_to_train, id), grayscale=True), dtype=np.float32).reshape(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS) / 255\n        \n    return x, y",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8f07154d5894e441136dffa6769b5b3427cd12a"
      },
      "cell_type": "code",
      "source": "x, y = prepare_training_sample(sample_size=4001) # Load everything (there are 4000 images)\nsalt_fraction = np.sum(np.sum(y, axis=1), axis=1)\nsalt_fraction = np.digitize(salt_fraction, np.linspace(0,1,10))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6474a713a39ae1062d1cf39bca0c5f5f7f626b8b"
      },
      "cell_type": "code",
      "source": "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, \n                                                      stratify=salt_fraction, \n                                                      random_state=RANDOM_SEED)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec6b061864033b2b91f8a22d1bb7d1a928e66a22"
      },
      "cell_type": "code",
      "source": "x_train = np.concatenate((x_train, x_train[:,:,::-1,:]), axis=0)\ny_train = np.concatenate((y_train, y_train[:,:,::-1,:]), axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1cfb7f6f0a4f4d07105c285f27370e063f360101"
      },
      "cell_type": "markdown",
      "source": "### Data Augmentation\nIn this section, we're going to flip the training images left to right and append them to the existing training set.  For validation purposes, I do not to add augmented images before splitting."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e65b60c0812471c6ee82a63735d648166e5d31c8"
      },
      "cell_type": "code",
      "source": "# Ideas and codes. \n# https://github.com/asanakoy/kaggle_carvana_segmentation/blob/master/albu/src/transforms.py\ndef clip(img, dtype, maxval):\n    return np.clip(img, 0, maxval).astype(dtype)\n\ndef randomize_brightness(image, limit=0.1):\n        alpha = 1.0 + limit * np.random.uniform(-1, 1)\n        # maxval = np.max(image[..., :3])\n        maxval = np.max(image)\n        dtype = image.dtype\n        image = clip(alpha * image, dtype, maxval)\n#        image[..., :3] = clip(alpha * image[...,:3], dtype, maxval)\n        return image \n\ndef deform(image, mask, num_steps=3, distort_limit=0.01):\n    height, width, channel = image.shape\n\n    x_step = width // num_steps\n    xx = np.zeros(width, np.float32)\n    prev = 0\n    for x in range(0, width, x_step):\n        start = x\n        end = x + x_step\n        if end > width:\n            end = width\n            cur = width\n        else:\n            cur = prev + x_step*(1+np.random.uniform(-distort_limit, distort_limit))\n\n        xx[start:end] = np.linspace(prev, cur, end-start)\n        prev = cur\n\n    y_step = height // num_steps\n    yy = np.zeros(height, np.float32)\n    prev = 0\n    for y in range(0, height, y_step):\n        start = y\n        end = y + y_step\n        if end > width:\n            end = height\n            cur = height\n        else:\n            cur = prev + y_step*(1+np.random.uniform(distort_limit, distort_limit))\n\n    yy[start:end] = np.linspace(prev, cur, end-start)\n    prev = cur\n\n    map_x, map_y = np.meshgrid(xx, yy)\n    map_x = map_x.astype(np.float32)\n    map_y = map_y.astype(np.float32)\n    image = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LINEAR, \n                    borderMode=cv2.BORDER_REFLECT_101).reshape(height, width, channel)\n    if mask is not None:\n        mask = cv2.remap(mask, map_x, map_y, interpolation=cv2.INTER_LINEAR, \n                         borderMode=cv2.BORDER_REFLECT_101).reshape(height, width, 1)\n\n    return image, mask\n    \ndef augment(image, mask, prob=0.5):\n    if np.random.uniform() < prob:\n        image = np.fliplr(image)\n        mask = np.fliplr(mask)\n        \n    if np.random.uniform() < prob:\n        image = randomize_brightness(image)\n\n    if np.random.uniform() < prob:\n        image, mask = deform(image, mask)\n\n    return image, mask \n\ndef generate_images(images, masks, batch_size=32):\n\n    n_samples, height, width, channels = images.shape\n    x_batch = np.zeros(shape=(batch_size, height, width, channels))\n    y_batch = np.zeros(shape=(batch_size, height, width, 1)) \n    while True:\n        indices = np.random.randint(0, n_samples, batch_size)\n        \n        for batch_index, data_index in enumerate(indices):\n            x_batch[batch_index], y_batch[batch_index] = augment(images[data_index], masks[data_index])\n                \n        yield (x_batch, y_batch)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a77e59b5cf6d982e580269dbd83a1b0743e25cb"
      },
      "cell_type": "code",
      "source": "'''\ngeneration_options = dict(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=0.0,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    zoom_range=0.0,\n    shear_range=0.0,\n    horizontal_flip=True,\n    vertical_flip=False,\n    zca_whitening=False\n)\n\nimage_generator = ImageDataGenerator(**generation_options)\nmask_generator  = ImageDataGenerator(**generation_options)\nimage_generator.fit(x_train, augment=True, seed=RANDOM_SEED)\nmask_generator.fit(y_train, augment=True, seed=RANDOM_SEED)\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1234dcc63094ba6e3f084ad2f5d7d9b3e67ed16"
      },
      "cell_type": "code",
      "source": "def dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) + 5.0 * dice_loss(y_true, y_pred)\n\niou_thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n\ndef iou(img_true, img_pred):\n    i = np.sum((img_true*img_pred) > 0)\n    u = np.sum((img_true + img_pred) > 0)\n    if u == 0:\n        return u\n    return i/u\n\ndef iou_metric(imgs_true, imgs_pred):\n    num_images = len(imgs_true)\n    scores = np.zeros(num_images)\n    \n    for i in range(num_images):\n        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n            scores[i] = 1\n        else:\n            scores[i] = (iou_thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n            \n    return scores.mean()\n\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\n\ndef get_iou_vector(A, B):\n    batch_size = A.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch]>0, B[batch]>0\n        \n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n        thresholds = np.arange(0.5, 1, 0.05)\n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        metric.append(np.mean(s))\n\n    return np.mean(metric)\n\ndef my_iou_metric(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0.5], tf.float64)\n\ndef my_iou_metric_2(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0], tf.float64)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c949a83bb6afc83be5281db431752b884a5f02f"
      },
      "cell_type": "code",
      "source": "def BatchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation == True:\n        x = BatchActivate(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, batch_activate = False):\n    x = BatchActivate(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    if batch_activate:\n        x = BatchActivate(x)\n    return x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1caf6f1ebe3c5df3c8c06771ee597f264172454e"
      },
      "cell_type": "code",
      "source": "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n    # 101 -> 50\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1, True)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(DropoutRatio/2)(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2, True)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio)(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4, True)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8, True)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = residual_block(convm,start_neurons * 16, True)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n    \n    # 12 -> 25\n    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(DropoutRatio)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n\n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(DropoutRatio)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n    \n    # 50 -> 101\n    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(DropoutRatio)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n    \n    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n    output_layer =  Activation('sigmoid')(output_layer_noActi)\n    \n    return output_layer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7bc18653d712acb9a5e4d2c638ec9fbd88481a27"
      },
      "cell_type": "code",
      "source": "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    gts = tf.reduce_sum(gt_sorted)\n    intersection = gts - tf.cumsum(gt_sorted)\n    union = gts + tf.cumsum(1. - gt_sorted)\n    jaccard = 1. - intersection / union\n    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        def treat_image(log_lab):\n            log, lab = log_lab\n            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n            log, lab = flatten_binary_scores(log, lab, ignore)\n            return lovasz_hinge_flat(log, lab)\n        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n\n    def compute_loss():\n        labelsf = tf.cast(labels, logits.dtype)\n        signs = 2. * labelsf - 1.\n        errors = 1. - logits * tf.stop_gradient(signs)\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n        gt_sorted = tf.gather(labelsf, perm)\n        grad = lovasz_grad(gt_sorted)\n        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n        return loss\n\n    # deal with the void prediction case (only void pixels)\n    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n                   lambda: tf.reduce_sum(logits) * 0.,\n                   compute_loss,\n                   strict=True,\n                   name=\"loss\"\n                   )\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = tf.reshape(scores, (-1,))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return scores, labels\n    valid = tf.not_equal(labels, ignore)\n    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vscores, vlabels\n\ndef lovasz_loss(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    #logits = K.log(y_pred / (1. - y_pred))\n    logits = y_pred #Jiaxin\n    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n    return loss",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90539f978e179d7d50990dcf485882ea83cd779d",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "model_checkpoint = ModelCheckpoint(\"keras.model\", save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(factor=5e-1, patience=5, min_lr=1e-6, verbose=1, monitor='val_my_iou_metric')\n#early_stopping = EarlyStopping(patience=15, verbose=1, monitor='val_my_iou_metric')\n\n#x_generator = image_generator.flow(x_train, batch_size=BATCH_SIZE, seed=RANDOM_SEED)\n#y_generator = mask_generator.flow(y_train, batch_size=BATCH_SIZE, seed=RANDOM_SEED)\n#train_generator = zip(x_generator, y_generator)\n\n#train_generator = generate_images(images=x_train, masks=y_train, batch_size=BATCH_SIZE)\n\n# model\ninput_layer = Input((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\noutput_layer = build_model(input_layer, 16, 0.5)\nmodel = Model(input_layer, output_layer)\n\noptimizer = optimizers.adam(lr = 0.005)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[my_iou_metric])\n\n#history = model.fit_generator(\n#    train_generator, \n#    validation_data=[x_valid, y_valid], \n#    epochs=MAX_EPOCHS,\n#    steps_per_epoch=BATCHES_PER_EPOCH,\n#    callbacks=[model_checkpoint, reduce_lr], \n#    shuffle=True\n#)\n\nhistory = model.fit(\n    x_train, y_train,\n    validation_data=[x_valid, y_valid], \n    epochs=EPOCHS_1,\n    batch_size=BATCH_SIZE_1,\n    callbacks=[model_checkpoint, reduce_lr], \n    verbose=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48d8ca8db87fac65889ac38a9fd97f032d56b478"
      },
      "cell_type": "code",
      "source": "model1 = load_model('keras.model', custom_objects={'my_iou_metric':my_iou_metric})\n\ninput_x = model1.layers[0].input\noutput_layer = model1.layers[-1].input\nmodel = Model(input_x, output_layer)\nc = optimizers.adam(lr=0.01)\n\nearly_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=30, verbose=1)\nmodel_checkpoint = ModelCheckpoint('keras.model', monitor='val_my_iou_metric_2', \n                                   mode = 'max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, \n                              min_lr=0.00005, verbose=1)\nmodel.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\nhistory = model.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=MAX_EPOCHS,\n                    batch_size=BATCH_SIZE_2,\n                    callbacks=[model_checkpoint, reduce_lr, early_stopping], \n                    verbose=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "789c0da451d616a08beb3083babba8a47dd05f99"
      },
      "cell_type": "code",
      "source": "model = load_model('keras.model', custom_objects={\n    'my_iou_metric_2':my_iou_metric_2,\n    'lovasz_loss':lovasz_loss\n})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7e4fb852eb132504cdf6eb04231e26c443aa5873"
      },
      "cell_type": "code",
      "source": "y_valid_pred = 0.5 * ( model.predict(x_valid) + model.predict(x_valid[:,:,::-1,:])[:,:,::-1,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "345d6e694db728a53263b8c4fe8480af5d747798"
      },
      "cell_type": "code",
      "source": "def filter_image(img):\n    if img.sum() < 100:\n        return np.zeros(img.shape)\n    else:\n        return img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94b95e562ea616be911d19cc4a5e232a11e702b1"
      },
      "cell_type": "code",
      "source": "thresholds = np.linspace(0.35, 0.65, 31)\nthresholds = np.log(thresholds / (1-thresholds))\nious = np.array([iou_metric(y_valid, [filter_image(img) for img in y_valid_pred > threshold]) for threshold in tqdm_notebook(thresholds)])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11270fcbb561edde56cd0f4017ab4d7f3aeb0606"
      },
      "cell_type": "code",
      "source": "threshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf6dc57ba8def5c975799aaadc66d61082ab3c9a"
      },
      "cell_type": "code",
      "source": "def rle_encode(im):\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8ca9ca77cf3f24f445564ec726ed58f422e3a51"
      },
      "cell_type": "code",
      "source": "def batch_predict(testing_ids, testing_path, batch_size=1000, threshold=0.5, model=None):\n    ''' Predict batches of images to save memory. '''\n        \n    total_batches = len(testing_ids) // batch_size\n    \n    data_store = []\n    for batch_index in tqdm_notebook(range(total_batches), total=total_batches):\n        if batch_index < (total_batches - 1):\n            ids = testing_ids[batch_index * batch_size:(batch_index + 1) * batch_size]\n        else:            \n            ids = testing_ids[batch_index * batch_size:]\n\n        test_df = pd.DataFrame({'id':ids})\n        test_df['image'] = [np.array(load_img(\"{}test/images/{}.png\".format(testing_path, id), grayscale=True)) / 255 for id in ids]\n        x_batch = np.array(test_df['image'].values.tolist()).reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n        y_pred = 0.5 * (model.predict(x_batch) + model.predict(x_batch[:,:,::-1,:])[:,:,::-1,:])\n        y_pred = np.round(y_pred > threshold)\n                \n        test_df['rle_mask'] = [rle_encode(y) for y in y_pred]\n        data_store.append(test_df.drop(columns=['image']))\n        \n    return pd.concat(data_store)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "74d69d083e64e4e2c31bffba2b6beb1e6c9df1b1"
      },
      "cell_type": "code",
      "source": "path_to_test = '../input/'\nextract_id = lambda x: x.split('.png')[0].split('/')[-1]\ntesting_ids = [extract_id(f) for f in glob.glob(path_to_test+'test/images/*.png')]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c3fb9fa86de1288705c78be552a1c316ee4a06f5"
      },
      "cell_type": "code",
      "source": "pred = batch_predict(testing_ids, path_to_test, batch_size=200, model=model, threshold=threshold_best)\npred.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c11cf67080baa148f24253d96bea29ee50836a05"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}